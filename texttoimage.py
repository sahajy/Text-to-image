# -*- coding: utf-8 -*-
"""texttoimage.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18tOktVDBdg3jvMja3iZiTZ-QTiOwC3Zt
"""

!pip install -q transformers diffusers moviepy gtts

import torch
from torch import float16
from diffusers import StableDiffusionPipeline
from IPython.display import clear_output
import gc

from IPython.display import clear_output
import gc
import torch

def clean_memory():
    gc.collect()
    torch.cuda.empty_cache()
    clear_output()
    print("ðŸ§¹ RAM Freed! Ready to continue.")

pipe = StableDiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2-1-base",
    torch_dtype=float16,  # Uses torch.float16
    variant="fp16",
    use_safetensors=True
).to("cuda")

try:
    image = pipe(
        "the knight fighting a dragon",
        height=512,  # Lower resolution = less RAM
        width=384,
        num_inference_steps=25  # Faster generation
    ).images[0]
    image.save("scene1.png")
finally:
    clean_memory()  # Ensures cleanup even if crash happens